# -*- coding: utf-8 -*-
"""Q3_c.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YJF_Q6c-Vl22lp84aibYE36tXIXNq6ON
"""

from google.colab import drive
drive.mount('/content/drive')

import scipy.io
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import math
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import numpy as np

#import data
dataset = scipy.io.loadmat('/content/drive/My Drive/ML assignment 3/dataset_b.mat')

#preprocessing on data
samples, label = dataset['samples'], dataset['labels']
df = pd.DataFrame(list(samples))
label = pd.DataFrame(label[0])
df['label'] = label

def k_fold_cross_validation(k,dataset):
	data_frame = pd.DataFrame(dataset)
	total_instance = data_frame.shape[0]
	k_fold_test = []
	start_range = 0
	end_range = 0
	k_fold_validation = {}
	for index in range(0,k):
		k_fold_validation[index+1] = {'test' : 1 ,
								'train' : pd.DataFrame()}
	for index in range(0,k):
		start_range = index*(math.floor(total_instance/k)) + 1
		end_range = (index+1)*(math.floor(total_instance/k))
		k_fold_validation[index+1]['test'] = data_frame[start_range:end_range]
	for index in range(0,k):
		k_fold_validation[index+1]['train'] = dataset.drop(k_fold_validation[index+1]['test'].index)
	return k_fold_validation

k_fold_validation_dataset = k_fold_cross_validation(5,df)
k_fold_validation_dataset

# grid search for C and gamma 
accuracy1=[]
for a in range (1 , 6):
    k=k_fold_validation_dataset[a]
    test_fold=k['test']
    train_fold=k['train']
    X=test_fold.drop('label', axis=1)
    y=test_fold['label']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)
    C=[0.1, 1, 10, 100, 1000] 
    gamma=[1, 0.1, 0.01, 0.001, 0.0001]
    for i in C:
      for j in gamma:
        svclassifier = SVC(decision_function_shape=custom_ovo,kernel='rbf',C=i,gamma=j)
        svclassifier.fit(X_train, y_train)
        y_pred = svclassifier.predict(X_test)
        print(accuracy_score(y_test,y_pred),i,j)
        accuracy1.append(accuracy_score(y_test,y_pred))

max(accuracy1)

#one vs one
def custom_ovo(df):
  target = 'label'
  unique_labels = np.unique(df[target])
  unique_labels.sort()

  models=[]
  for i in range(len(unique_labels)):
      for  j in range(i + 1, len(unique_labels)):
          df = df[(df[target] == unique_labels[i]) | (df[target] == unique_labels[j])]
          data = []
          for row in range(len(df)):
              mydict={}
              arr = df.iloc[[row]]
              for i in arr.keys():
                  mydict[i] = float(arr[i])
              data.append(mydict)              
          df = pd.DataFrame(data)
  return df

accuracy=[]
sum=0
for i in range (1 , 6):
  k=k_fold_validation_dataset[i]
  test_fold=k['test']
  train_fold=k['train']
  X=test_fold.drop('label', axis=1)
  y=test_fold['label']
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)
  svclassifier = SVC(decision_function_shape=custom_ovo,kernel='rbf',C=1,gamma=1)
  svclassifier.fit(X_train, y_train)
  y_pred = svclassifier.predict(X_test)
  accuracy.append(accuracy_score(y_test,y_pred))
accuracy

#find mean accuracy
for i in range(5):
  sum=sum+accuracy[i]
mean=sum/5
print("mean accuracy",mean)





