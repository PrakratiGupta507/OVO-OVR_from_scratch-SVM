# -*- coding: utf-8 -*-
"""Q1.(a)ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15kjbT07nag3cpuBXJT3K21qsqPVnntth
"""

from google.colab import drive
drive.mount('/content/gdrive')

def unpickle(file):
    import pickle
    with open(file, 'rb') as fo:
        dict = pickle.load(fo, encoding='bytes')
    return dict

import matplotlib.pyplot as plt
import numpy as np 
import pandas as pd
from scipy.io import loadmat
from sklearn.decomposition import PCA

train_1 = unpickle('/content/gdrive/My Drive/ML assignment 3/data_batch_1')
train_2 = unpickle('/content/gdrive/My Drive/ML assignment 3/data_batch_2')
train_3 = unpickle('/content/gdrive/My Drive/ML assignment 3/data_batch_3')
train_4 = unpickle('/content/gdrive/My Drive/ML assignment 3/data_batch_4')
train_5 = unpickle('/content/gdrive/My Drive/ML assignment 3/data_batch_5')
test_data = unpickle('/content/gdrive/My Drive/ML assignment 3/test_batch')

labels = np.vstack((train_1[b'labels'], train_2[b'labels'], train_3[b'labels'], train_4[b'labels'], train_5[b'labels']))
data = np.vstack((train_1[b'data'], train_2[b'data'], train_3[b'data'], train_4[b'data'], train_5[b'data']))
data = np.array(data)

pca = PCA(0.9)
principalComponents = pca.fit_transform(data)
list_values = pca.explained_variance_ratio_
value = 0 
for i in range(len(pca.explained_variance_ratio_)):
  value = value+list_values[i]

value

plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance');

