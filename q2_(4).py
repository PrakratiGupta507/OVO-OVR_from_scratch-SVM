# -*- coding: utf-8 -*-
"""Q2(4).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XUmM3T6lpZIKIx_2qgcxEB5CyCJO1AEa
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn import svm

import matplotlib.pyplot as plt
from matplotlib.axes._axes import _log as matplotlib_axes_logger
from mpl_toolkits import mplot3d
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from matplotlib.colors import ListedColormap

import scipy.io
mat = scipy.io.loadmat('/content/drive/My Drive/ML assignment 3/dataset_a.mat')

samples, label = mat['samples'], mat['labels']
df = pd.DataFrame(list(samples))
label = pd.DataFrame(label[0])
df['label'] = label
x=df[0]
y=df[1]
z=df['label']
data = pd.DataFrame({"X_Value": x, "Y_Value": y, "Category": z})
data

y = data["Category"]
X = data.drop(["Category"],axis=1)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

C = [0.001, 0.01, 0.1, 1, 10, 100]
for i in C:
  SVM = svm.SVC(kernel = "linear", C = i)
  SVM.fit(X_train.values, y_train.values)
  y_pred = SVM.predict(X_test.values)
  print("C : ",i,"Accuracy :",np.mean(y_pred==y_test.values))

SVM = svm.SVC(kernel = "linear", C = 1, gamma=0.7)
SVM.fit(X_train.values, y_train.values)
y_pred = SVM.predict(X_test.values)

def plotHyperplane(w1,w2,b,):
    plt.figure(figsize=(6,5))
    x_1 = np.linspace(int(np.min(X_train.values)),int(np.max(X_train.values)))
    x_2 = -(w1*x_1+b)/w2
    positive_plane = -(w1*x_1 + b +1)/w2
    negative_plane = -(w1*x_1+b-1)/w2
    plt.plot(x_1,x_2,'k-',label="HyperPlane")
    plt.plot(x_1,positive_plane,'k--',label="Positive Plane")
    plt.plot(x_1,negative_plane,'k--',label="Negative Plane")
    plt.legend("topleft")
    plt.title("C: 1 , Accuracy : 0.6725")
    sns.scatterplot(X_train.values[:,0],X_train.values[:,1],c=y_train.values,palette="bright")
    plt.show()

plotHyperplane(SVM.coef_[0,0],SVM.coef_[0,1],SVM.intercept_)

C = [0.001, 0.01, 0.1, 1, 10, 100]
g = [0.001, 0.01, 0.1, 1, 10, 100]
classifiers=[]
for i in C:
  for j in g:
    SVM = svm.SVC(kernel = "rbf", C = i,gamma=j)
    SVM.fit(X_train.values, y_train.values)
    y_pred = SVM.predict(X_test.values)
    classifiers.append((i, j, SVM))
    print("C : ",i,"G : ",j,"Accuracy :",np.mean(y_pred==y_test.values))

SVM = svm.SVC(kernel = "rbf", C = 0.001,gamma = 1)
SVM.fit(X_train.values, y_train.values)
y_pred = SVM.predict(X_test.values)

def plotrbf(model, ax=None, plot_support=True):
    if ax is None:
        ax = plt.gca()
    x_li = ax.get_xlim()
    y_li = ax.get_ylim()
    x = np.linspace(x_li[0], x_li[1], 30)
    y = np.linspace(y_li[0], y_li[1], 30)
    Y_value, X_value = np.meshgrid(y, x)
    a = np.vstack([X_value.ravel(), Y_value.ravel()]).T
    P = model.decision_function(a).reshape(X_value.shape)
    ax.contour(X_value, Y_value, P, colors='k',levels=[-1, 0, 1], alpha=0.9,linestyles=['--', '-', '--'])
    if plot_support:
        ax.scatter(model.support_vectors_[:, 0],model.support_vectors_[:, 1],s=300, linewidth=1, facecolors='none',);
    ax.set_xlim(x_li)
    ax.set_ylim(y_li)

sns.scatterplot(X_train.values[:, 0], X_train.values[:, 1], c=y_train.values, s=50, cmap='Wistia')
plotrbf(SVM, plot_support=False)

